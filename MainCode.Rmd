---
title: "BA Project2"
author: "Diwei Zhu, Gabriela Caballero, Kunyang Que, Ullas Srivastava, Yangxin Liu"
date: "11/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = T)
library(ggplot2)
library(dataQualityR)
library(magrittr)
library(dplyr)
library(caret)
```

# Part I: Data Preprocessing

## 1.1 Load Data

```{r}
data_origin<-read.csv("application_train.csv",header = T)
score_data_origin<-read.csv("applications_to_score.csv",header = T)

#external
previous_data_origin<-read.csv("previous_application.csv",header = T)
creditcard_data_origin<-read.csv("credit_card_balance.csv",header = T)
```

```{r}
data<-data_origin
score_data<-data_origin
dataLogisticModel<-data

previous_data<-previous_data_origin
creditcard_data<-creditcard_data_origin
```

### Data Exploration
```{r}
# review the "balance" of the positive class we are about to predict
table(data$TARGET)
prop.table(table(data$TARGET))
barplot(table(data$TARGET))

#CHECK DATA QUALITY 
# checkDataQuality(data=data, 
#                  out.file.num ="dq_loans_num.csv", 
#                  out.file.cat= "dq_loans_cat.csv")
# dq_num<-read.csv("dq_loans_cat.csv")
# View(dq_num)
# 
# dq_cat<-read.csv("dq_loans_cat.csv")
# View(dq_cat)
```

## 1.2 Summary

```{r}
colnames(score_data)
```

```{r}
colnames(data)
for (i in colnames(data)) {
  print(paste("========",i,"========="))
  if (is.character(data[[i]])) {
     print(unique(data[[i]]) )
  } else if (is.logical(data[[i]])) {
     print(table(data[[i]]))
  } else {
    print(summary(data[[i]]))
  }
}

```

### Reducing Data Set

```{r}
index <- sample(1:nrow(data),(.1)*nrow(data))  # technique to reduce dataset
data <- data [index, ]
dataLogisticModel <- dataLogisticModel [index, ]
```

## 1.3 Data Cleaning

### Removing the XNAs from CODE_GENDER
```{r}
data<-subset(data,!data$CODE_GENDER %in% "XNA")
dataLogisticModel<-subset(dataLogisticModel,!dataLogisticModel$CODE_GENDER %in% "XNA")
```

### Calculating quartiles for AMT_INCOME_TOTAL
```{r}
Q <- quantile(data$AMT_INCOME_TOTAL, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(data$AMT_INCOME_TOTAL)
up <- Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
# head(subset(data, data$AMT_INCOME_TOTAL < (Q[2]+1.5*iqr)))
# There are 15052 rows with "outliers" income total amount above the 75% of the data, we only removed the biggest outlier and kept the rest
data<-subset(data, data$AMT_INCOME_TOTAL!=117000000)
dataLogisticModel<-subset(dataLogisticModel, dataLogisticModel$AMT_INCOME_TOTAL!=117000000)
```

### Removing 11 NAs from AMT_ANNUITY

```{r}
data<-subset(data, !is.na(data$AMT_ANNUITY))
dataLogisticModel<-subset(dataLogisticModel, !is.na(dataLogisticModel$AMT_ANNUITY))
```

### Removing 262 NAs from AMT_GOODS_PRICE

```{r}
data<-subset(data, !is.na(data$AMT_GOODS_PRICE))
dataLogisticModel<-subset(dataLogisticModel, !is.na(dataLogisticModel$AMT_GOODS_PRICE))
```

### Removing 962 rows with empty data "" from NAME_TYPE_SUITE

```{r}
data<-subset(data, !data$NAME_TYPE_SUITE=="")
dataLogisticModel<-subset(dataLogisticModel, !dataLogisticModel$NAME_TYPE_SUITE=="")
```

### Changing the Unemployed and pensioned employed days to 0 to give less importance to the paramater but only for linear and logistic models, leaving it as it is for random forest

```{r}
dataLogisticModel$DAYS_EMPLOYED_POSITIVE<-ifelse(data$DAYS_EMPLOYED>0,1,0)
dataLogisticModel$DAYS_EMPLOYED<- ifelse(dataLogisticModel$DAYS_EMPLOYED>0,0,dataLogisticModel$DAYS_EMPLOYED)
#Creating a flag column for them
```

#### For random forest

```{r}
#Handling positive numbers DAYS_EMPLOYED
#Creating a flag column for them
data$DAYS_EMPLOYED_POSITIVE<-ifelse(data$DAYS_EMPLOYED>0,1,0)
#Replacing those values with Non numbers values
data$DAYS_EMPLOYED<-ifelse(data$DAYS_EMPLOYED>0,NaN,data$DAYS_EMPLOYED)

```

### OWN_CAR_AGE NAs are because the person does not own a car and that's why we do not have info about the age of th car, leaving the NAs since they make sense. Code below that proves it.

```{r}
# for ( i in colnames(data)) {
#   if (data$FLAG_OWN_CAR=='N'&&!is.na(data$OWN_CAR_AGE)) {
#     loansNAswithoutcar=1+loansNAswithoutcar;
#   } else {
#     if (data$FLAG_OWN_CAR=='Y'&&is.na(data$OWN_CAR_AGE)) {
#       loansNAWithCar=1+loansNAWithCar
#     }
#   }
# }
# loansNAswithoutcar
```

### Removing outliers from OBS_30_CNT_SOCIAL_CIRCLE, DEF_30_CNT_SOCIAL_CIRCLE, OBS_60_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE

```{r}
data = data[!data$OBS_30_CNT_SOCIAL_CIRCLE > 47,]
data = data[!data$DEF_30_CNT_SOCIAL_CIRCLE > 8,]
data = data[!data$OBS_60_CNT_SOCIAL_CIRCLE > 47,]
data = data[!data$DEF_60_CNT_SOCIAL_CIRCLE > 8,]


dataLogisticModel = dataLogisticModel[!dataLogisticModel$OBS_30_CNT_SOCIAL_CIRCLE > 47,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$DEF_30_CNT_SOCIAL_CIRCLE > 8,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$OBS_60_CNT_SOCIAL_CIRCLE > 47,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$DEF_60_CNT_SOCIAL_CIRCLE > 8,]
```

###  Deal with AMT_REQ_CREDIT_BUREAU

```{r}
# add the new column "AMT_REQ_CREDIT_BUREAU", which means the total Number of inquiries to Credit Bureau about the client one year before application
data$AMT_REQ_CREDIT_BUREAU<-data$AMT_REQ_CREDIT_BUREAU_HOUR + 
  data$AMT_REQ_CREDIT_BUREAU_DAY +
  data$AMT_REQ_CREDIT_BUREAU_WEEK +
  data$AMT_REQ_CREDIT_BUREAU_MON + 
  data$AMT_REQ_CREDIT_BUREAU_QRT +
  data$AMT_REQ_CREDIT_BUREAU_YEAR

print(paste("======== AMT_REQ_CREDIT_BUREAU ========="))
print(summary(data$AMT_REQ_CREDIT_BUREAU))

dataLogisticModel$AMT_REQ_CREDIT_BUREAU<-dataLogisticModel$AMT_REQ_CREDIT_BUREAU_HOUR + 
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_DAY +
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_WEEK +
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_MON + 
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_QRT +
 dataLogisticModel$AMT_REQ_CREDIT_BUREAU_YEAR


dataLogisticModel<-mutate(dataLogisticModel, AMT_REQ_CREDIT_BUREAU=if_else(is.na(dataLogisticModel$AMT_REQ_CREDIT_BUREAU), 0, 
                                     if_else(AMT_REQ_CREDIT_BUREAU >= 0 & AMT_REQ_CREDIT_BUREAU < 2, 1, 
                                             if_else(AMT_REQ_CREDIT_BUREAU >= 2 & AMT_REQ_CREDIT_BUREAU < 4, 2, 3))))

```

```{r}
# delete columns
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_HOUR)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_DAY)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_WEEK)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_MON)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_QRT)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_YEAR)

dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_HOUR)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_DAY)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_WEEK)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_MON)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_QRT)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_YEAR)
```


### Deleting 1 NA from CNT_FAM_MEMBERS

```{r}
data<-subset(data, !data$CNT_FAM_MEMBERS=="NA")

dataLogisticModel<-subset(dataLogisticModel, !data$CNT_FAM_MEMBERS=="NA")
#table(data$CNT_FAM_MEMBERS)
```


### Changing the OCCUPATION_TYPE blanks variables to "Others"'

```{r}

data$OCCUPATION_TYPE[data$OCCUPATION_TYPE==""]<- "Others"
dataLogisticModel$OCCUPATION_TYPE[dataLogisticModel$OCCUPATION_TYPE==""]<- "Others"

```


#### Cleaning outliers for HOUR_APPR_PROCESS_START
```{r}
Q <- quantile(data$HOUR_APPR_PROCESS_START, probs=c(.25, .75), na.rm = FALSE)

iqr <- IQR(data$HOUR_APPR_PROCESS_START)

up <-  Q[2]+1.5*iqr # Upper Range  

low<- Q[1]-1.5*iqr # Lower Range

data<- subset(data, data$HOUR_APPR_PROCESS_START > (Q[1] - 1.5*iqr) & data$HOUR_APPR_PROCESS_START < (Q[2]+1.5*iqr))

dataLogisticModel<- subset(dataLogisticModel, dataLogisticModel$HOUR_APPR_PROCESS_START > (Q[1] - 1.5*iqr) & dataLogisticModel$HOUR_APPR_PROCESS_START < (Q[2]+1.5*iqr))

```


### Turning NA to averages for EXT_SOURCE_3
```{r}

data$EXT_SOURCE_3[data$EXT_SOURCE_3=="NA"]<- 0.51

dataLogisticModel$EXT_SOURCE_3[dataLogisticModel$EXT_SOURCE_3=="NA"]<- 0.51
```

### Changing the ORGANIZATION_TYPE XNA variables to "Unknown"'
```{r}

data$ORGANIZATION_TYPE[data$ORGANIZATION_TYPE=="XNA"]<- "Unknown"

dataLogisticModel$ORGANIZATION_TYPE[dataLogisticModel$ORGANIZATION_TYPE=="XNA"]<- "Unknown"

#table(data$ORGANIZATION_TYPE)
```


### data cleaning for building info
```{r new}
# data cleaning

temp<- data ##input
## removing avg & MEDI
temp<-temp[,-which(names(temp) %in% c("APARTMENTS_AVG","BASEMENTAREA_AVG","YEARS_BEGINEXPLUATATION_AVG","YEARS_BUILD_AVG","COMMONAREA_AVG","ELEVATORS_AVG","ENTRANCES_AVG","FLOORSMAX_AVG","FLOORSMIN_AVG","LANDAREA_AVG","LIVINGAPARTMENTS_AVG","LIVINGAREA_AVG","NONLIVINGAPARTMENTS_AVG","NONLIVINGAREA_AVG","APARTMENTS_MEDI","BASEMENTAREA_MEDI","YEARS_BEGINEXPLUATATION_MEDI","YEARS_BUILD_MEDI","COMMONAREA_MEDI","ELEVATORS_MEDI","ENTRANCES_MEDI","FLOORSMAX_MEDI","FLOORSMIN_MEDI","LANDAREA_MEDI","LIVINGAPARTMENTS_MEDI","LIVINGAREA_MEDI","NONLIVINGAPARTMENTS_MEDI","NONLIVINGAREA_MEDI"))]
data<-temp ##output

temp<- dataLogisticModel ##input
## removing avg & MEDI
temp<-temp[,-which(names(temp) %in% c("APARTMENTS_AVG","BASEMENTAREA_AVG","YEARS_BEGINEXPLUATATION_AVG","YEARS_BUILD_AVG","COMMONAREA_AVG","ELEVATORS_AVG","ENTRANCES_AVG","FLOORSMAX_AVG","FLOORSMIN_AVG","LANDAREA_AVG","LIVINGAPARTMENTS_AVG","LIVINGAREA_AVG","NONLIVINGAPARTMENTS_AVG","NONLIVINGAREA_AVG","APARTMENTS_MEDI","BASEMENTAREA_MEDI","YEARS_BEGINEXPLUATATION_MEDI","YEARS_BUILD_MEDI","COMMONAREA_MEDI","ELEVATORS_MEDI","ENTRANCES_MEDI","FLOORSMAX_MEDI","FLOORSMIN_MEDI","LANDAREA_MEDI","LIVINGAPARTMENTS_MEDI","LIVINGAREA_MEDI","NONLIVINGAPARTMENTS_MEDI","NONLIVINGAREA_MEDI"))]
dataLogisticModel<-temp ##output

```

## feature engineering for building info
```{r warning=FALSE}
# feature engineering
temp1 <- dataLogisticModel ##linear data
temp2 <- data ##tree data
library(parallel)
qrtEncode <- function(x,dat) {
  if (is.na(x)) {
    return("NA")
  }
    if (x < dat[1]) {
      return("0-25%")
    } 
  if (x < dat[2]) {
      return("25-50%")
    } 
  if (x < dat[3]) {
      return("50-75%")
    } 
      return("75-100%")
}
ZeroEncode <- function(x, dat) {
  if (is.na(x)) {
    return("NA")
  }
  if (x == 0) {
    return("ZERO")
  }
  return("OVER ZERO")
}
#multithread

clus <- makeCluster(detectCores())
clusterExport(clus,"qrtEncode")
clusterExport(clus,"ZeroEncode")


temp1$APARTMENTS_MODE_FLAG <-  ifelse(is.na(temp1$APARTMENTS_MODE), 0, 1)#NA-0,else-1
temp1$APARTMENTS_MODE<-ifelse(is.na(temp1$APARTMENTS_MODE), 0, temp1$APARTMENTS_MODE)
temp2$APARTMENTS_MODE<-parLapply(clus,X=temp2$APARTMENTS_MODE,fun=qrtEncode,dat=quantile(temp2$APARTMENTS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$APARTMENTS_MODE<-unlist(temp2$APARTMENTS_MODE)

temp1$BASEMENTAREA_MODE_FLAG <-  ifelse(is.na(temp1$BASEMENTAREA_MODE), 0, 1)#NA-0,else-1
temp1$BASEMENTAREA_MODE<-ifelse(is.na(temp1$BASEMENTAREA_MODE), 0, temp1$BASEMENTAREA_MODE)
temp2$BASEMENTAREA_MODE<-parLapply(clus,X=temp2$BASEMENTAREA_MODE,fun=qrtEncode,dat=quantile(temp2$BASEMENTAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$BASEMENTAREA_MODE<-unlist(temp2$BASEMENTAREA_MODE)

temp1$YEARS_BEGINEXPLUATATION_MODE <-ifelse(is.na(temp1$YEARS_BEGINEXPLUATATION_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$YEARS_BEGINEXPLUATATION_MODE <-ifelse(is.na(temp2$YEARS_BEGINEXPLUATATION_MODE), 0, 1)#have-1,NA-0,overwrite

temp1$YEARS_BUILD_MODE_FLAG <-  ifelse(is.na(temp1$YEARS_BUILD_MODE), 0, 1)#NA-0,else-1
temp1$YEARS_BUILD_MODE<-ifelse(is.na(temp1$YEARS_BUILD_MODE), 0, temp1$YEARS_BUILD_MODE)
temp2$YEARS_BUILD_MODE<-parLapply(clus,X=temp2$YEARS_BUILD_MODE,fun=qrtEncode,dat=quantile(temp2$YEARS_BUILD_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$YEARS_BUILD_MODE<-unlist(temp2$YEARS_BUILD_MODE)

temp1$COMMONAREA_MODE <-ifelse(is.na(temp1$COMMONAREA_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$COMMONAREA_MODE <-ifelse(is.na(temp2$COMMONAREA_MODE), 0, 1)#have-1,NA-0,overwrite

temp1$ELEVATORS_MODE_FLAG <-  ifelse(is.na(temp1$ELEVATORS_MODE), 0, 1)#NA-0,else-1
temp1$ELEVATORS_MODE<-ifelse(is.na(temp1$ELEVATORS_MODE), 0, temp1$ELEVATORS_MODE)
temp2$ELEVATORS_MODE<-parLapply(clus,X=temp2$ELEVATORS_MODE,fun=ZeroEncode,dat=quantile(temp2$ELEVATORS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$ELEVATORS_MODE<-unlist(temp2$ELEVATORS_MODE)

temp1$ENTRANCES_MODE_FLAG <-  ifelse(is.na(temp1$ENTRANCES_MODE), 0, 1)#NA-0,else-1
temp1$ENTRANCES_MODE<-ifelse(is.na(temp1$ENTRANCES_MODE), 0, temp1$ENTRANCES_MODE)
temp2$ENTRANCES_MODE<-parLapply(clus,X=temp2$ENTRANCES_MODE,fun=qrtEncode,dat=quantile(temp2$ENTRANCES_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$ENTRANCES_MODE<-unlist(temp2$ENTRANCES_MODE)

temp1$FLOORSMAX_MODE_FLAG <-  ifelse(is.na(temp1$FLOORSMAX_MODE), 0, 1)#NA-0,else-1
temp1$FLOORSMAX_MODE<-ifelse(is.na(temp1$FLOORSMAX_MODE), 0, temp1$FLOORSMAX_MODE)
temp2$FLOORSMAX_MODE<-parLapply(clus,X=temp2$FLOORSMAX_MODE,fun=qrtEncode,dat=quantile(temp2$FLOORSMAX_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$FLOORSMAX_MODE<-unlist(temp2$FLOORSMAX_MODE)

temp1$FLOORSMIN_MODE_FLAG <-  ifelse(is.na(temp1$FLOORSMIN_MODE), 0, 1)#NA-0,else-1
temp1$FLOORSMIN_MODE<-ifelse(is.na(temp1$FLOORSMIN_MODE), 0, temp1$FLOORSMIN_MODE)
temp2$FLOORSMIN_MODE<-parLapply(clus,X=temp2$FLOORSMIN_MODE,fun=qrtEncode,dat=quantile(temp2$FLOORSMIN_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$FLOORSMIN_MODE<-unlist(temp2$FLOORSMIN_MODE)

temp1$LANDAREA_MODE_FLAG <-  ifelse(is.na(temp1$LANDAREA_MODE), 0, 1)#NA-0,else-1
temp1$LANDAREA_MODE<-ifelse(is.na(temp1$LANDAREA_MODE), 0, temp1$LANDAREA_MODE)
temp2$LANDAREA_MODE<-parLapply(clus,X=temp2$LANDAREA_MODE,fun=qrtEncode,dat=quantile(temp2$LANDAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LANDAREA_MODE<-unlist(temp2$LANDAREA_MODE)

temp1$LIVINGAPARTMENTS_MODE_FLAG <-  ifelse(is.na(temp1$LIVINGAPARTMENTS_MODE), 0, 1)#NA-0,else-1
temp1$LIVINGAPARTMENTS_MODE<-ifelse(is.na(temp1$LIVINGAPARTMENTS_MODE), 0, temp1$LIVINGAPARTMENTS_MODE)
temp2$LIVINGAPARTMENTS_MODE<-parLapply(clus,X=temp2$LIVINGAPARTMENTS_MODE,fun=qrtEncode,dat=quantile(temp2$LIVINGAPARTMENTS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LIVINGAPARTMENTS_MODE<-unlist(temp2$LIVINGAPARTMENTS_MODE)

temp1$LIVINGAREA_MODE_FLAG <-  ifelse(is.na(temp1$LIVINGAREA_MODE), 0, 1)#NA-0,else-1
temp1$LIVINGAREA_MODE<-ifelse(is.na(temp1$LIVINGAREA_MODE), 0, temp1$LIVINGAREA_MODE)
temp2$LIVINGAREA_MODE<-parLapply(clus,X=temp2$LIVINGAREA_MODE,fun=qrtEncode,dat=quantile(temp2$LIVINGAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LIVINGAREA_MODE<-unlist(temp2$LIVINGAREA_MODE)

temp1$NONLIVINGAPARTMENTS_MODE <-ifelse(is.na(temp1$NONLIVINGAPARTMENTS_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$NONLIVINGAPARTMENTS_MODE <-ifelse(is.na(temp2$NONLIVINGAPARTMENTS_MODE), 0, 1)#have-1,NA-0,overwrite


temp1$NONLIVINGAREA_MODE_FLAG <-  ifelse(is.na(temp1$NONLIVINGAREA_MODE), 0, 1)#NA-0,else-1
temp1$NONLIVINGAREA_MODE<-ifelse(is.na(temp1$NONLIVINGAREA_MODE), 0, temp1$NONLIVINGAREA_MODE)
temp2$NONLIVINGAREA_MODE<-parLapply(clus,X=temp2$NONLIVINGAREA_MODE,fun=ZeroEncode,dat=quantile(temp2$NONLIVINGAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$NONLIVINGAREA_MODE<-unlist(temp2$NONLIVINGAREA_MODE)

# OWN_CAR_AGE
temp1$OWN_CAR_AGE <-  ifelse(is.na(temp1$OWN_CAR_AGE), 0, 1)#NA-0,else-1
temp1$OWN_CAR_AGE<-ifelse(is.na(temp1$OWN_CAR_AGE), 0, temp1$OWN_CAR_AGE)
temp2$OWN_CAR_AGE<-parLapply(clus,X=temp2$OWN_CAR_AGE,fun=ZeroEncode,dat=quantile(temp2$OWN_CAR_AGE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$OWN_CAR_AGE<-unlist(temp2$OWN_CAR_AGE)

# EXT_SOURCE_2
temp1$EXT_SOURCE_1 <-  ifelse(is.na(temp1$EXT_SOURCE_1), 0, 1)#NA-0,else-1
temp1$EXT_SOURCE_1<-ifelse(is.na(temp1$EXT_SOURCE_1), 0, temp1$EXT_SOURCE_1)
temp2$EXT_SOURCE_1<-parLapply(clus,X=temp2$EXT_SOURCE_1,fun=ZeroEncode,dat=quantile(temp2$EXT_SOURCE_1, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$EXT_SOURCE_1<-unlist(temp2$EXT_SOURCE_1)

temp1$EXT_SOURCE_2 <-  ifelse(is.na(temp1$EXT_SOURCE_2), 0, 1)#NA-0,else-1
temp1$EXT_SOURCE_2<-ifelse(is.na(temp1$EXT_SOURCE_2), 0, temp1$EXT_SOURCE_2)
temp2$EXT_SOURCE_2<-parLapply(clus,X=temp2$EXT_SOURCE_2,fun=ZeroEncode,dat=quantile(temp2$EXT_SOURCE_2, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$EXT_SOURCE_2<-unlist(temp2$EXT_SOURCE_2)

temp1$EXT_SOURCE_3 <-  ifelse(is.na(temp1$EXT_SOURCE_3), 0, 1)#NA-0,else-1
temp1$EXT_SOURCE_3<-ifelse(is.na(temp1$EXT_SOURCE_3), 0, temp1$EXT_SOURCE_2)
temp2$EXT_SOURCE_3<-parLapply(clus,X=temp2$EXT_SOURCE_3,fun=ZeroEncode,dat=quantile(temp2$EXT_SOURCE_3, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$EXT_SOURCE_3<-unlist(temp2$EXT_SOURCE_3)

temp1$TOTALAREA_MODE <-  ifelse(is.na(temp1$TOTALAREA_MODE), 0, 1)#NA-0,else-1
temp1$TOTALAREA_MODE<-ifelse(is.na(temp1$TOTALAREA_MODE), 0, temp1$TOTALAREA_MODE)
temp2$TOTALAREA_MODE<-parLapply(clus,X=temp2$TOTALAREA_MODE,fun=ZeroEncode,dat=quantile(temp2$TOTALAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$TOTALAREA_MODE<-unlist(temp2$TOTALAREA_MODE)

stopCluster(clus)
#output
dataLogisticModel<-temp1 ## linear data
data<-temp2 ## tree data
```

### Drop column FLAG_MOBIL
```{r}
data<-subset(data, select = -FLAG_MOBIL)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_MOBIL)
```

### Deal with column FLAG_DOCUMENT

```{r}
# Remove outliers
data<-subset(data, FLAG_DOCUMENT_2 == 0)
data<-subset(data, FLAG_DOCUMENT_4 == 0)
data<-subset(data, FLAG_DOCUMENT_7 == 0)
data<-subset(data, FLAG_DOCUMENT_10 == 0)
data<-subset(data, FLAG_DOCUMENT_12 == 0)
data<-subset(data, FLAG_DOCUMENT_17 == 0)
data<-subset(data, FLAG_DOCUMENT_19 == 0)
data<-subset(data, FLAG_DOCUMENT_20 == 0)
data<-subset(data, FLAG_DOCUMENT_21 == 0)

dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_2 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_4 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_7 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_10 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_12 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_17 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_19 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_20 == 0)
dataLogisticModel<-subset(dataLogisticModel, FLAG_DOCUMENT_21 == 0)

# Drop Column

data<-subset(data, select = -FLAG_DOCUMENT_2)
data<-subset(data, select = -FLAG_DOCUMENT_4)
data<-subset(data, select = -FLAG_DOCUMENT_7)
data<-subset(data, select = -FLAG_DOCUMENT_10)
data<-subset(data, select = -FLAG_DOCUMENT_12)
data<-subset(data, select = -FLAG_DOCUMENT_17)
data<-subset(data, select = -FLAG_DOCUMENT_19)
data<-subset(data, select = -FLAG_DOCUMENT_20)
data<-subset(data, select = -FLAG_DOCUMENT_21)

dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_2)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_4)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_7)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_10)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_12)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_17)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_19)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_20)
dataLogisticModel<-subset(dataLogisticModel, select = -FLAG_DOCUMENT_21)
```

## using credit card data
```{r creditcard}

#input
temp1<-creditcard_data
temp2<- dataLogisticModel#logistic
temp3<-data #tree 
#note
#month balance- length of record
#amt balance - how many money need to pay the bank in the latest month
#amt limit actual - the max credit bank arpoved
#status - the last application status
#
library(dplyr)
library(parallel)
qrtEncode <- function(x,dat) {
  if (is.na(x)) {
    return("NA")
  }
    if (x < dat[1]) {
      return("0-25%")
    } 
  if (x < dat[2]) {
      return("25-50%")
    } 
  if (x < dat[3]) {
      return("50-75%")
    } 
      return("75-100%")
}
ZeroEncode <- function(x, dat) {
  if (is.na(x)) {
    return("NA")
  }
  if (x == 0) {
    return("ZERO")
  }
  return("OVER ZERO")
}

clus <- makeCluster(detectCores())
clusterExport(clus,"qrtEncode")
clusterExport(clus,"ZeroEncode")

credit_merge<-aggregate(temp1[c("MONTHS_BALANCE")],by=temp1["SK_ID_CURR"],FUN = length)
credit_merge$MAX_Month<-aggregate(temp1[c("MONTHS_BALANCE")],by=temp1["SK_ID_CURR"],FUN = max)[["MONTHS_BALANCE"]]
colnames(credit_merge)<-c("SK_ID_CURR","CREDIT_CARD_RECORD_COUNT","MONTHS_BALANCE")
credit_merge<-left_join(credit_merge,creditcard_data[c("SK_ID_CURR","MONTHS_BALANCE","AMT_BALANCE","AMT_CREDIT_LIMIT_ACTUAL","NAME_CONTRACT_STATUS")], by=c("SK_ID_CURR","MONTHS_BALANCE"))
credit_merge<-credit_merge[,-which(names(credit_merge)=="MONTHS_BALANCE")]
credit_merge$NAME_CONTRACT_STATUS<-ifelse(credit_merge$NAME_CONTRACT_STATUS%in%c("Active","Completed"),credit_merge$NAME_CONTRACT_STATUS,"Others")
temp2<-left_join(temp2,credit_merge, by="SK_ID_CURR") 
temp3<-left_join(temp3,credit_merge, by="SK_ID_CURR") 

temp2$CREDIT_CARD_RECORD_COUNTE_FLAG <-  ifelse(is.na(temp2$CREDIT_CARD_RECORD_COUNT), 0, 1)#NA-0,else-1
temp2$CREDIT_CARD_RECORD_COUNT<-ifelse(is.na(temp2$CREDIT_CARD_RECORD_COUNT), 0, temp2$CREDIT_CARD_RECORD_COUNT)
temp3$CREDIT_CARD_RECORD_COUNT <-parLapply(clus,X=temp3$CREDIT_CARD_RECORD_COUNT,fun=qrtEncode,dat=quantile(temp3$CREDIT_CARD_RECORD_COUNT, prob = c(0.25,0.5,0.75),na.rm = T))
temp3$CREDIT_CARD_RECORD_COUNT<-unlist(temp3$CREDIT_CARD_RECORD_COUNT)

temp2$AMT_BALANCE_FLAG <-  ifelse(is.na(temp2$AMT_BALANCE), 0, 1)#NA-0,else-1
temp2$AMT_BALANCE<-ifelse(is.na(temp2$AMT_BALANCE), 0, temp2$AMT_BALANCE)
temp3$AMT_BALANCE <-parLapply(clus,X=temp3$AMT_BALANCE,fun=ZeroEncode,dat=quantile(temp3$AMT_BALANCE, prob = c(0.25,0.5,0.75),na.rm = T))
temp3$AMT_BALANCE<-unlist(temp3$AMT_BALANCE)

temp2$AMT_CREDIT_LIMIT_ACTUAL_FLAG <-  ifelse(is.na(temp2$AMT_CREDIT_LIMIT_ACTUAL), 0, 1)#NA-0,else-1
temp2$AMT_CREDIT_LIMIT_ACTUAL<-ifelse(is.na(temp2$AMT_CREDIT_LIMIT_ACTUAL), 0, temp2$AMT_CREDIT_LIMIT_ACTUAL)
temp3$AMT_CREDIT_LIMIT_ACTUAL <-parLapply(clus,X=temp3$AMT_CREDIT_LIMIT_ACTUAL,fun=qrtEncode,dat=quantile(temp3$AMT_CREDIT_LIMIT_ACTUAL, prob = c(0.25,0.5,0.75),na.rm = T))
temp3$AMT_CREDIT_LIMIT_ACTUAL<-unlist(temp3$AMT_CREDIT_LIMIT_ACTUAL)

#active status is cat data,fill NA
temp2$NAME_CONTRACT_STATUS <-  ifelse(is.na(temp2$NAME_CONTRACT_STATUS), "NA", temp2$NAME_CONTRACT_STATUS)
temp3$NAME_CONTRACT_STATUS <-  ifelse(is.na(temp3$NAME_CONTRACT_STATUS), "NA", temp3$NAME_CONTRACT_STATUS)


#output
dataLogisticModel<-temp2
data<-temp3
#
```


### using previous application data
```{r prevApp, warning=FALSE}

#input
temp1<-previous_data
temp2<-dataLogisticModel #logistic
temp3<-data #tree 
#note
#month balance- length of record
#amt balance - how many money need to pay the bank in the latest month
#amt limit actual - the max credit bank arpoved
#status - the last application status
#
library(dplyr)
library(parallel)
qrtEncode <- function(x,dat) {
  if (is.na(x)) {
    return("NA")
  }
    if (x < dat[1]) {
      return("0-25%")
    } 
  if (x < dat[2]) {
      return("25-50%")
    } 
  if (x < dat[3]) {
      return("50-75%")
    } 
      return("75-100%")
}
ZeroEncode <- function(x, dat) {
  if (is.na(x)) {
    return("NA")
  }
  if (x == 0) {
    return("ZERO")
  }
  return("OVER ZERO")
}

clus <- makeCluster(detectCores())
clusterExport(clus,"qrtEncode")
clusterExport(clus,"ZeroEncode")

temp1<- subset(temp1,temp1$FLAG_LAST_APPL_PER_CONTRACT=="Y"&temp1$NFLAG_LAST_APPL_IN_DAY==1)

preapp_merge<-aggregate(temp1[c("NAME_CONTRACT_TYPE")],by=temp1["SK_ID_CURR"],FUN = length)
colnames(preapp_merge)<-c("SK_ID_CURR","PREV_RECORD_COUNT")



#####Cash loans
temp<-subset(temp1,temp1$NAME_CONTRACT_TYPE=="Cash loans")
temp4<-aggregate(temp[c("NAME_CONTRACT_TYPE")],by=temp["SK_ID_CURR"],FUN = length)

temp5<-aggregate(temp[c("SK_ID_PREV")],by=temp[c("SK_ID_CURR","NAME_CONTRACT_STATUS")],FUN = length)
#approved
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Approved")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","APPROVED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#refused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Refused")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","REFUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#unused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Unused offer")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","UNUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )

colnames(temp4)<-c("SK_ID_CURR","CASH_LOANS_COUNT","APPROVE_COUNT","REFUSED_COUNT","UNUSED_COUNT")
temp4$CASH_LOANS_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$REFUSED_COUNT),0,temp4$REFUSED_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)/temp4$CASH_LOANS_COUNT
temp4$APPROVE_COUNT<-ifelse(is.nan(temp4$APPROVE_COUNT),NA,temp4$APPROVE_COUNT)
colnames(temp4)<-c("SK_ID_CURR","CASH_LOANS_COUNT","CASH_LOANS_APPROVE_RATE")
temp4<-temp4[,1:3]
preapp_merge<-left_join(preapp_merge,temp4, by="SK_ID_CURR") 
preapp_merge$CASH_LOANS_COUNT<-ifelse(is.na(preapp_merge$CASH_LOANS_COUNT),0,preapp_merge$CASH_LOANS_COUNT)
####


####Consumer loans
temp<-subset(temp1,temp1$NAME_CONTRACT_TYPE=="Consumer loans")
temp4<-aggregate(temp[c("NAME_CONTRACT_TYPE")],by=temp["SK_ID_CURR"],FUN = length)

temp5<-aggregate(temp[c("SK_ID_PREV")],by=temp[c("SK_ID_CURR","NAME_CONTRACT_STATUS")],FUN = length)
#approved
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Approved")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","APPROVED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#refused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Refused")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","REFUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#unused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Unused offer")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","UNUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )

colnames(temp4)<-c("SK_ID_CURR","COMSUMER_LOANS_COUNT","APPROVE_COUNT","REFUSED_COUNT","UNUSED_COUNT")
temp4$COMSUMER_LOANS_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$REFUSED_COUNT),0,temp4$REFUSED_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)/temp4$COMSUMER_LOANS_COUNT
temp4$APPROVE_COUNT<-ifelse(is.nan(temp4$APPROVE_COUNT),NA,temp4$APPROVE_COUNT)
colnames(temp4)<-c("SK_ID_CURR","COMSUMER_LOANS_COUNT","CONSUMER_LOANS_APPROVE_RATE")
temp4<-temp4[,1:3]
preapp_merge<-left_join(preapp_merge,temp4, by="SK_ID_CURR") 
preapp_merge$COMSUMER_LOANS_COUNT<-ifelse(is.na(preapp_merge$COMSUMER_LOANS_COUNT),0,preapp_merge$COMSUMER_LOANS_COUNT)


##Revolving loans
temp<-subset(temp1,temp1$NAME_CONTRACT_TYPE=="Revolving loans")
temp4<-aggregate(temp[c("NAME_CONTRACT_TYPE")],by=temp["SK_ID_CURR"],FUN = length)

temp5<-aggregate(temp[c("SK_ID_PREV")],by=temp[c("SK_ID_CURR","NAME_CONTRACT_STATUS")],FUN = length)
#approved
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Approved")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","APPROVED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#refused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Refused")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","REFUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )
#unused
temp6<-subset(temp5,temp5$NAME_CONTRACT_STATUS=="Unused offer")
temp6<-temp6[,-which(names(temp6)=="NAME_CONTRACT_STATUS")]
colnames(temp6)<-c("SK_ID_CURR","UNUSED_COUNT")
temp4<-left_join(temp4,temp6,by="SK_ID_CURR" )

colnames(temp4)<-c("SK_ID_CURR","REVOLVING_LOANS_COUNT","APPROVE_COUNT","REFUSED_COUNT","UNUSED_COUNT")
temp4$REVOLVING_LOANS_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$REFUSED_COUNT),0,temp4$REFUSED_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)+ifelse(is.na(temp4$UNUSED_COUNT),0,temp4$UNUSED_COUNT)
temp4$APPROVE_COUNT<-ifelse(is.na(temp4$APPROVE_COUNT),0,temp4$APPROVE_COUNT)/temp4$REVOLVING_LOANS_COUNT
temp4$APPROVE_COUNT<-ifelse(is.nan(temp4$APPROVE_COUNT),NA,temp4$APPROVE_COUNT)
colnames(temp4)<-c("SK_ID_CURR","REVOLVING_LOANS_COUNT","REVOLVING_LOANS_APPROVE_RATE")
temp4<-temp4[,1:3]
preapp_merge<-left_join(preapp_merge,temp4, by="SK_ID_CURR") 
preapp_merge$REVOLVING_LOANS_COUNT<-ifelse(is.na(preapp_merge$REVOLVING_LOANS_COUNT),0,preapp_merge$REVOLVING_LOANS_COUNT)

temp4<-aggregate(temp1[c("CNT_PAYMENT")],by=temp1["SK_ID_CURR"],FUN = mean)
colnames(temp4)<-c("SK_ID_CURR","CNT_PAYMENT_AVG")
preapp_merge<-left_join(preapp_merge,temp4, by="SK_ID_CURR") 


temp2<-left_join(temp2,preapp_merge, by="SK_ID_CURR") #linear
temp3<-left_join(temp3,preapp_merge, by="SK_ID_CURR") ##tree


for (i in c("PREV_RECORD_COUNT", "CASH_LOANS_COUNT","CASH_LOANS_APPROVE_RATE","COMSUMER_LOANS_COUNT" ,"CONSUMER_LOANS_APPROVE_RATE","REVOLVING_LOANS_COUNT","REVOLVING_LOANS_APPROVE_RATE")){
  temp2[[i]] <-ifelse(is.na(temp2[[i]]), 0, 1)#have-1,NA-0,overwrite
temp3[[i]] <-ifelse(is.na(temp3[[i]]), 0, 1)#have-1,NA-0,overwrite
}


temp2$CNT_PAYMENT_AVG_FLAG <-  ifelse(is.na(temp2$CNT_PAYMENT_AVG), 0, 1)#NA-0,else-1
temp2$CNT_PAYMENT_AVG<-ifelse(is.na(temp2$CNT_PAYMENT_AVG), 0, temp2$CNT_PAYMENT_AVG)

temp3$CNT_PAYMENT_AVG<-parLapply(clus,X=temp3$CNT_PAYMENT_AVG,fun=qrtEncode,dat=quantile(temp3$CNT_PAYMENT_AVG, prob = c(0.25,0.5,0.75),na.rm = T))
temp3$CNT_PAYMENT_AVG<-unlist(temp3$CNT_PAYMENT_AVG)

dataLogisticModel<-temp2 #logistic
data<-temp3 #tree 

```

## 1.4 Encoding Categorical Variables
```{r}
#Dummification of categorical variables logistic model

WRTENABLE= F
dataLogisticModel$TARGET<-as.numeric(dataLogisticModel$TARGET)
dataDummyLogistic <- dummyVars("~.",data=dataLogisticModel, fullRank=F)
data.dummified.logistic <- as.data.frame(predict(dataDummyLogistic,dataLogisticModel))
data.dummified.logistic$TARGET <- as.factor(data.dummified.logistic$TARGET)
if(WRTENABLE){
  data.raw.dummy<-write.csv(data.dummified.logistic,file="data.dummified.logistic.csv") 
}




##Dummification of categorical variables tree model

data$TARGET<-as.numeric(data$TARGET)
dataDummy <- dummyVars("~.",data=data, fullRank=F)
data.dummified <- as.data.frame(predict(dataDummy,data))
data.dummified$TARGET <- as.factor(data.dummified$TARGET)
if(WRTENABLE){
  data.raw.dummy<-write.csv(data.dummified,file="data.dummified.csv")
}
#Fixing dummified variables' names
names(data.dummified.logistic)<-make.names(names(data.dummified.logistic),unique = TRUE)
names(data.dummified)<-make.names(names(data.dummified),unique = TRUE)
```

```{r}
my_num_data <- data[, sapply(data, is.numeric)]
cor(my_num_data, use = "complete.obs", method = "pearson")
```

==============================================pca=================================================



```{r}
data_pca<-data.dummified.logistic

library(psych)
data_pca<-data.matrix(data_pca)
df.cor<-cor(data_pca[,-1])

fa.parallel(data_pca[,-1], fa = "pc", n.iter = 100, show.legend = F, main = "Scree plot with parallel analysis")
#sapply(data_pca, class)
#std_data<-scale(data_pca[3:ncol(data_pca)])
#rownames(std_data)=data[[1]]

#std_data=as.data.frame(std_data)

#std_data_pca=princomp(std_data,cor=TRUE)
#summary(df.pr,loadings=TRUE)
```

```{r}
library(psych)
pc<-principal(data_pca[,-1], nfactors = 2, score = T, rotate = "varimax")
summary(pc,loadings=TRUE)
```

==============================================pca=================================================


```{r}
outcomeName <- "TARGET"
predictorNames <- names(data.dummified.logistic)[names(data.dummified.logistic) != outcomeName]
predictorNames

set.seed(1234)  # setting seed to reproduce results of random sampling
split<-(.80)
trainingRowIndex <- sample(1:nrow(data.dummified.logistic),(split)*nrow(data.dummified.logistic))  # row indices for training data
trainingData <- data.dummified.logistic[trainingRowIndex, ]  # model training data
testData  <- data.dummified.logistic[-trainingRowIndex, ]   # test data

#Model
model <- as.formula(paste("TARGET~", paste(names(trainingData[-2]), 
                                           collapse="+")))
target.lm <- glm(model, data=trainingData, family = binomial(link = "logit"))  # build the model
# Review diagnostic measures
summary(target.lm)

# Step 3: Calculate prediction accuracy and error rates
response<- ifelse(predict(target.lm, testData, type = "response")>.5, 1, 0) 
class(response)
confusionMatrix(table(response,testData$TARGET))
```


```{r}
std_data_pca=princomp(std_data,cor=TRUE)
summary(df.pr,loadings=TRUE)
```

