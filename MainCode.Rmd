---
title: "BA Project2"
author: "Diwei Zhu, Gabriela Caballero, Kunyang Que, Ullas Srivastava, Yangxin Liu"
date: "11/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache = T)
library(ggplot2)
library(dataQualityR)
library(magrittr)
library(dplyr)
library(caret)
```

# Part I: Data Preprocessing

## 1.1 Load Data

```{r}
data<- read.csv("application_train.csv",header = T)
score_data<-read.csv("applications_to_score.csv",header = T)
dataLogisticModel<-data

#external
previous_data<-read.csv("previous_application.csv",header = T)
creditcard_data<- read.csv("credit_card_balance.csv",header = T)

```
### Data Exploration
```{r}
# review the "balance" of the positive class we are about to predict
table(data$TARGET)
prop.table(table(data$TARGET))
barplot(table(data$TARGET))

#CHECK DATA QUALITY 
# checkDataQuality(data=data, 
#                  out.file.num ="dq_loans_num.csv", 
#                  out.file.cat= "dq_loans_cat.csv")
# dq_num<-read.csv("dq_loans_cat.csv")
# View(dq_num)
# 
# dq_cat<-read.csv("dq_loans_cat.csv")
# View(dq_cat)
```


## 1.2 Summary

```{r}
colnames(score_data)
```

```{r}
colnames(data)
for (i in colnames(data)) {
  print(paste("========",i,"========="))
  if (is.character(data[[i]])) {
     print(unique(data[[i]]) )
  } else if (is.logical(data[[i]])) {
     print(table(data[[i]]))
  } else {
    print(summary(data[[i]]))
  }
}

```
### Reducing Data Set

```{r}
index <- sample(1:nrow(data),(.1)*nrow(data))  # technique to reduce dataset
data <- data [index, ]
dataLogisticModel <- dataLogisticModel [index, ]
```

## 1.3 Data Cleaning

### Removing the XNAs from CODE_GENDER
```{r}
data<-subset(data,!data$CODE_GENDER %in% "XNA")
dataLogisticModel<-subset(dataLogisticModel,!dataLogisticModel$CODE_GENDER %in% "XNA")
```

### Calculating quartiles for AMT_INCOME_TOTAL
```{r}
Q <- quantile(data$AMT_INCOME_TOTAL, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(data$AMT_INCOME_TOTAL)
up <- Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
# head(subset(data, data$AMT_INCOME_TOTAL < (Q[2]+1.5*iqr)))
# There are 15052 rows with "outliers" income total amount above the 75% of the data, we only removed the biggest outlier and kept the rest
data<-subset(data, data$AMT_INCOME_TOTAL!=117000000)
dataLogisticModel<-subset(dataLogisticModel, dataLogisticModel$AMT_INCOME_TOTAL!=117000000)
```

### Removing 11 NAs from AMT_ANNUITY

```{r}
data<-subset(data, !is.na(data$AMT_ANNUITY))
dataLogisticModel<-subset(dataLogisticModel, !is.na(dataLogisticModel$AMT_ANNUITY))
```

### Removing 262 NAs from AMT_GOODS_PRICE

```{r}
data<-subset(data, !is.na(data$AMT_GOODS_PRICE))
dataLogisticModel<-subset(dataLogisticModel, !is.na(dataLogisticModel$AMT_GOODS_PRICE))
```

### Removing 962 rows with empty data "" from NAME_TYPE_SUITE

```{r}
data<-subset(data, !data$NAME_TYPE_SUITE=="")
dataLogisticModel<-subset(dataLogisticModel, !dataLogisticModel$NAME_TYPE_SUITE=="")
```

### Changing the Unemployed and pensioned employed days to 0 to give less importance to the paramater but only for linear and logistic models, leaving it as it is for random forest

```{r}
dataLogisticModel$DAYS_EMPLOYED_POSITIVE<-ifelse(data$DAYS_EMPLOYED>0,1,0)
dataLogisticModel$DAYS_EMPLOYED<- ifelse(dataLogisticModel$DAYS_EMPLOYED>0,0,dataLogisticModel$DAYS_EMPLOYED)
#Creating a flag column for them
```

#### For random forest

```{r}
#Handling positive numbers DAYS_EMPLOYED
#Creating a flag column for them
data$DAYS_EMPLOYED_POSITIVE<-ifelse(data$DAYS_EMPLOYED>0,1,0)
#Replacing those values with Non numbers values
data$DAYS_EMPLOYED<-ifelse(data$DAYS_EMPLOYED>0,NaN,data$DAYS_EMPLOYED)

```

### OWN_CAR_AGE NAs are because the person does not own a car and that's why we do not have info about the age of th car, leaving the NAs since they make sense. Code below that proves it.

```{r}
# for ( i in colnames(data)) {
#   if (data$FLAG_OWN_CAR=='N'&&!is.na(data$OWN_CAR_AGE)) {
#     loansNAswithoutcar=1+loansNAswithoutcar;
#   } else {
#     if (data$FLAG_OWN_CAR=='Y'&&is.na(data$OWN_CAR_AGE)) {
#       loansNAWithCar=1+loansNAWithCar
#     }
#   }
# }
# loansNAswithoutcar
```

### Removing outliers from OBS_30_CNT_SOCIAL_CIRCLE, DEF_30_CNT_SOCIAL_CIRCLE, OBS_60_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE

```{r}
data = data[!data$OBS_30_CNT_SOCIAL_CIRCLE > 47,]
data = data[!data$DEF_30_CNT_SOCIAL_CIRCLE > 8,]
data = data[!data$OBS_60_CNT_SOCIAL_CIRCLE > 47,]
data = data[!data$DEF_60_CNT_SOCIAL_CIRCLE > 8,]


dataLogisticModel = dataLogisticModel[!dataLogisticModel$OBS_30_CNT_SOCIAL_CIRCLE > 47,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$DEF_30_CNT_SOCIAL_CIRCLE > 8,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$OBS_60_CNT_SOCIAL_CIRCLE > 47,]
dataLogisticModel = dataLogisticModel[!dataLogisticModel$DEF_60_CNT_SOCIAL_CIRCLE > 8,]
```

###  Deal with AMT_REQ_CREDIT_BUREAU

```{r}
# add the new column "AMT_REQ_CREDIT_BUREAU", which means the total Number of inquiries to Credit Bureau about the client one year before application
data$AMT_REQ_CREDIT_BUREAU<-data$AMT_REQ_CREDIT_BUREAU_HOUR + 
  data$AMT_REQ_CREDIT_BUREAU_DAY +
  data$AMT_REQ_CREDIT_BUREAU_WEEK +
  data$AMT_REQ_CREDIT_BUREAU_MON + 
  data$AMT_REQ_CREDIT_BUREAU_QRT +
  data$AMT_REQ_CREDIT_BUREAU_YEAR

print(paste("======== AMT_REQ_CREDIT_BUREAU ========="))
print(summary(data$AMT_REQ_CREDIT_BUREAU))

dataLogisticModel$AMT_REQ_CREDIT_BUREAU<-dataLogisticModel$AMT_REQ_CREDIT_BUREAU_HOUR + 
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_DAY +
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_WEEK +
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_MON + 
  dataLogisticModel$AMT_REQ_CREDIT_BUREAU_QRT +
 dataLogisticModel$AMT_REQ_CREDIT_BUREAU_YEAR


dataLogisticModel<-mutate(dataLogisticModel, AMT_REQ_CREDIT_BUREAU=if_else(is.na(dataLogisticModel$AMT_REQ_CREDIT_BUREAU), 0, 
                                     if_else(AMT_REQ_CREDIT_BUREAU >= 0 & AMT_REQ_CREDIT_BUREAU < 2, 1, 
                                             if_else(AMT_REQ_CREDIT_BUREAU >= 2 & AMT_REQ_CREDIT_BUREAU < 4, 2, 3))))

```

```{r}
# delete columns
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_HOUR)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_DAY)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_WEEK)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_MON)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_QRT)
data<-subset(data, select = -AMT_REQ_CREDIT_BUREAU_YEAR)

dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_HOUR)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_DAY)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_WEEK)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_MON)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_QRT)
dataLogisticModel<-subset(dataLogisticModel, select = -AMT_REQ_CREDIT_BUREAU_YEAR)
```


### Deleting 1 NA from CNT_FAM_MEMBERS

```{r}
data<-subset(data, !data$CNT_FAM_MEMBERS=="NA")

dataLogisticModel<-subset(dataLogisticModel, !data$CNT_FAM_MEMBERS=="NA")
#table(data$CNT_FAM_MEMBERS)
```


### Changing the OCCUPATION_TYPE blanks variables to "Others"'

```{r}

data$OCCUPATION_TYPE[data$OCCUPATION_TYPE==""]<- "Others"
dataLogisticModel$OCCUPATION_TYPE[dataLogisticModel$OCCUPATION_TYPE==""]<- "Others"

```


#### Cleaning outliers for HOUR_APPR_PROCESS_START
```{r}
Q <- quantile(data$HOUR_APPR_PROCESS_START, probs=c(.25, .75), na.rm = FALSE)

iqr <- IQR(data$HOUR_APPR_PROCESS_START)

up <-  Q[2]+1.5*iqr # Upper Range  

low<- Q[1]-1.5*iqr # Lower Range

data<- subset(data, data$HOUR_APPR_PROCESS_START > (Q[1] - 1.5*iqr) & data$HOUR_APPR_PROCESS_START < (Q[2]+1.5*iqr))

dataLogisticModel<- subset(dataLogisticModel, dataLogisticModel$HOUR_APPR_PROCESS_START > (Q[1] - 1.5*iqr) & dataLogisticModel$HOUR_APPR_PROCESS_START < (Q[2]+1.5*iqr))

```


### Turning NA to averages for EXT_SOURCE_3
```{r}

data$EXT_SOURCE_3[data$EXT_SOURCE_3=="NA"]<- 0.51

dataLogisticModel$EXT_SOURCE_3[dataLogisticModel$EXT_SOURCE_3=="NA"]<- 0.51
```

### Changing the ORGANIZATION_TYPE XNA variables to "Unknown"'
```{r}

data$ORGANIZATION_TYPE[data$ORGANIZATION_TYPE=="XNA"]<- "Unknown"

dataLogisticModel$ORGANIZATION_TYPE[dataLogisticModel$ORGANIZATION_TYPE=="XNA"]<- "Unknown"

#table(data$ORGANIZATION_TYPE)
```


### data cleaning for building info
```{r new}
# data cleaning

temp<- data ##input
## removing avg & MEDI
temp<-temp[,-which(names(temp) %in% c("APARTMENTS_AVG","BASEMENTAREA_AVG","YEARS_BEGINEXPLUATATION_AVG","YEARS_BUILD_AVG","COMMONAREA_AVG","ELEVATORS_AVG","ENTRANCES_AVG","FLOORSMAX_AVG","FLOORSMIN_AVG","LANDAREA_AVG","LIVINGAPARTMENTS_AVG","LIVINGAREA_AVG","NONLIVINGAPARTMENTS_AVG","NONLIVINGAREA_AVG","APARTMENTS_MEDI","BASEMENTAREA_MEDI","YEARS_BEGINEXPLUATATION_MEDI","YEARS_BUILD_MEDI","COMMONAREA_MEDI","ELEVATORS_MEDI","ENTRANCES_MEDI","FLOORSMAX_MEDI","FLOORSMIN_MEDI","LANDAREA_MEDI","LIVINGAPARTMENTS_MEDI","LIVINGAREA_MEDI","NONLIVINGAPARTMENTS_MEDI","NONLIVINGAREA_MEDI"))]
data<-temp ##output

temp<- dataLogisticModel ##input
## removing avg & MEDI
temp<-temp[,-which(names(temp) %in% c("APARTMENTS_AVG","BASEMENTAREA_AVG","YEARS_BEGINEXPLUATATION_AVG","YEARS_BUILD_AVG","COMMONAREA_AVG","ELEVATORS_AVG","ENTRANCES_AVG","FLOORSMAX_AVG","FLOORSMIN_AVG","LANDAREA_AVG","LIVINGAPARTMENTS_AVG","LIVINGAREA_AVG","NONLIVINGAPARTMENTS_AVG","NONLIVINGAREA_AVG","APARTMENTS_MEDI","BASEMENTAREA_MEDI","YEARS_BEGINEXPLUATATION_MEDI","YEARS_BUILD_MEDI","COMMONAREA_MEDI","ELEVATORS_MEDI","ENTRANCES_MEDI","FLOORSMAX_MEDI","FLOORSMIN_MEDI","LANDAREA_MEDI","LIVINGAPARTMENTS_MEDI","LIVINGAREA_MEDI","NONLIVINGAPARTMENTS_MEDI","NONLIVINGAREA_MEDI"))]
dataLogisticModel<-temp ##output

```

## feature engineering for building info
```{r warning=FALSE}
# feature engineering



temp1 <- dataLogisticModel ##linear data
temp2 <- data ##tree data
library(parallel)
qrtEncode <- function(x,dat) {
  if (is.na(x)) {
    return("NA")
  }
    if (x < dat[1]) {
      return("0-25%")
    } 
  if (x < dat[2]) {
      return("25-50%")
    } 
  if (x < dat[3]) {
      return("50-75%")
    } 
      return("75-100%")
}
ZeroEncode <- function(x, dat) {
  if (is.na(x)) {
    return("NA")
  }
  if (x == 0) {
    return("ZERO")
  }
  return("OVER ZERO")
}
#multithread

clus <- makeCluster(detectCores())
clusterExport(clus,"qrtEncode")
clusterExport(clus,"ZeroEncode")


temp1$APARTMENTS_MODE_FLAG <-  ifelse(is.na(temp1$APARTMENTS_MODE), 0, 1)#NA-0,else-1
temp1$APARTMENTS_MODE<-ifelse(is.na(temp1$APARTMENTS_MODE), 0, temp1$APARTMENTS_MODE)
temp2$APARTMENTS_MODE<-parLapply(clus,X=temp2$APARTMENTS_MODE,fun=qrtEncode,dat=quantile(temp2$APARTMENTS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$APARTMENTS_MODE<-unlist(temp2$APARTMENTS_MODE)

temp1$BASEMENTAREA_MODE_FLAG <-  ifelse(is.na(temp1$BASEMENTAREA_MODE), 0, 1)#NA-0,else-1
temp1$BASEMENTAREA_MODE<-ifelse(is.na(temp1$BASEMENTAREA_MODE), 0, temp1$BASEMENTAREA_MODE)
temp2$BASEMENTAREA_MODE<-parLapply(clus,X=temp2$BASEMENTAREA_MODE,fun=qrtEncode,dat=quantile(temp2$BASEMENTAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$BASEMENTAREA_MODE<-unlist(temp2$BASEMENTAREA_MODE)

temp1$YEARS_BEGINEXPLUATATION_MODE <-ifelse(is.na(temp1$YEARS_BEGINEXPLUATATION_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$YEARS_BEGINEXPLUATATION_MODE <-ifelse(is.na(temp2$YEARS_BEGINEXPLUATATION_MODE), 0, 1)#have-1,NA-0,overwrite

temp1$YEARS_BUILD_MODE_FLAG <-  ifelse(is.na(temp1$YEARS_BUILD_MODE), 0, 1)#NA-0,else-1
temp1$YEARS_BUILD_MODE<-ifelse(is.na(temp1$YEARS_BUILD_MODE), 0, temp1$YEARS_BUILD_MODE)
temp2$YEARS_BUILD_MODE<-parLapply(clus,X=temp2$YEARS_BUILD_MODE,fun=qrtEncode,dat=quantile(temp2$YEARS_BUILD_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$YEARS_BUILD_MODE<-unlist(temp2$YEARS_BUILD_MODE)

temp1$COMMONAREA_MODE <-ifelse(is.na(temp1$COMMONAREA_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$COMMONAREA_MODE <-ifelse(is.na(temp2$COMMONAREA_MODE), 0, 1)#have-1,NA-0,overwrite

temp1$ELEVATORS_MODE_FLAG <-  ifelse(is.na(temp1$ELEVATORS_MODE), 0, 1)#NA-0,else-1
temp1$ELEVATORS_MODE<-ifelse(is.na(temp1$ELEVATORS_MODE), 0, temp1$ELEVATORS_MODE)
temp2$ELEVATORS_MODE<-parLapply(clus,X=temp2$ELEVATORS_MODE,fun=ZeroEncode,dat=quantile(temp2$ELEVATORS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$ELEVATORS_MODE<-unlist(temp2$ELEVATORS_MODE)

temp1$ENTRANCES_MODE_FLAG <-  ifelse(is.na(temp1$ENTRANCES_MODE), 0, 1)#NA-0,else-1
temp1$ENTRANCES_MODE<-ifelse(is.na(temp1$ENTRANCES_MODE), 0, temp1$ENTRANCES_MODE)
temp2$ENTRANCES_MODE<-parLapply(clus,X=temp2$ENTRANCES_MODE,fun=qrtEncode,dat=quantile(temp2$ENTRANCES_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$ENTRANCES_MODE<-unlist(temp2$ENTRANCES_MODE)

temp1$FLOORSMAX_MODE_FLAG <-  ifelse(is.na(temp1$FLOORSMAX_MODE), 0, 1)#NA-0,else-1
temp1$FLOORSMAX_MODE<-ifelse(is.na(temp1$FLOORSMAX_MODE), 0, temp1$FLOORSMAX_MODE)
temp2$FLOORSMAX_MODE<-parLapply(clus,X=temp2$FLOORSMAX_MODE,fun=qrtEncode,dat=quantile(temp2$FLOORSMAX_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$FLOORSMAX_MODE<-unlist(temp2$FLOORSMAX_MODE)

temp1$FLOORSMIN_MODE_FLAG <-  ifelse(is.na(temp1$FLOORSMIN_MODE), 0, 1)#NA-0,else-1
temp1$FLOORSMIN_MODE<-ifelse(is.na(temp1$FLOORSMIN_MODE), 0, temp1$FLOORSMIN_MODE)
temp2$FLOORSMIN_MODE<-parLapply(clus,X=temp2$FLOORSMIN_MODE,fun=qrtEncode,dat=quantile(temp2$FLOORSMIN_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$FLOORSMIN_MODE<-unlist(temp2$FLOORSMIN_MODE)

temp1$LANDAREA_MODE_FLAG <-  ifelse(is.na(temp1$LANDAREA_MODE), 0, 1)#NA-0,else-1
temp1$LANDAREA_MODE<-ifelse(is.na(temp1$LANDAREA_MODE), 0, temp1$LANDAREA_MODE)
temp2$LANDAREA_MODE<-parLapply(clus,X=temp2$LANDAREA_MODE,fun=qrtEncode,dat=quantile(temp2$LANDAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LANDAREA_MODE<-unlist(temp2$LANDAREA_MODE)

temp1$LIVINGAPARTMENTS_MODE_FLAG <-  ifelse(is.na(temp1$LIVINGAPARTMENTS_MODE), 0, 1)#NA-0,else-1
temp1$LIVINGAPARTMENTS_MODE<-ifelse(is.na(temp1$LIVINGAPARTMENTS_MODE), 0, temp1$LIVINGAPARTMENTS_MODE)
temp2$LIVINGAPARTMENTS_MODE<-parLapply(clus,X=temp2$LIVINGAPARTMENTS_MODE,fun=qrtEncode,dat=quantile(temp2$LIVINGAPARTMENTS_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LIVINGAPARTMENTS_MODE<-unlist(temp2$LIVINGAPARTMENTS_MODE)

temp1$LIVINGAREA_MODE_FLAG <-  ifelse(is.na(temp1$LIVINGAREA_MODE), 0, 1)#NA-0,else-1
temp1$LIVINGAREA_MODE<-ifelse(is.na(temp1$LIVINGAREA_MODE), 0, temp1$LIVINGAREA_MODE)
temp2$LIVINGAREA_MODE<-parLapply(clus,X=temp2$LIVINGAREA_MODE,fun=qrtEncode,dat=quantile(temp2$LIVINGAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$LIVINGAREA_MODE<-unlist(temp2$LIVINGAREA_MODE)

temp1$NONLIVINGAPARTMENTS_MODE <-ifelse(is.na(temp1$NONLIVINGAPARTMENTS_MODE), 0, 1)#have-1,NA-0,overwrite
temp2$NONLIVINGAPARTMENTS_MODE <-ifelse(is.na(temp2$NONLIVINGAPARTMENTS_MODE), 0, 1)#have-1,NA-0,overwrite


temp1$NONLIVINGAREA_MODE_FLAG <-  ifelse(is.na(temp1$NONLIVINGAREA_MODE), 0, 1)#NA-0,else-1
temp1$NONLIVINGAREA_MODE<-ifelse(is.na(temp1$NONLIVINGAREA_MODE), 0, temp1$NONLIVINGAREA_MODE)
temp2$NONLIVINGAREA_MODE<-parLapply(clus,X=temp2$NONLIVINGAREA_MODE,fun=ZeroEncode,dat=quantile(temp2$NONLIVINGAREA_MODE, prob = c(0.25,0.5,0.75),na.rm = T))
temp2$NONLIVINGAREA_MODE<-unlist(temp2$NONLIVINGAREA_MODE)

stopCluster(clus)
#output
dataLogisticModel<-temp1 ## linear data
data<-temp2 ## tree data


```


## 1.4 Encoding Categorical Variables
```{r}
#Dummification of categorical variables logistic model

dataLogisticModel$TARGET<-as.numeric(dataLogisticModel$TARGET)
dataDummyLogistic <- dummyVars("~.",data=dataLogisticModel, fullRank=F)
data.dummified.logistic <- as.data.frame(predict(dataDummyLogistic,dataLogisticModel))
data.dummified.logistic$TARGET <- as.factor(data.dummified.logistic$TARGET)
data.raw.dummy<-write.csv(data.dummified.logistic,file="data.dummified.logistic.csv")

#Fixing dummified variables' names
names(data.dummified.logistic)<-make.names(names(data.dummified.logistic),unique = TRUE)

##Dummification of categorical variables tree model

data$TARGET<-as.numeric(data$TARGET)
dataDummy <- dummyVars("~.",data=data, fullRank=F)
data.dummified <- as.data.frame(predict(dataDummy,data))
data.dummified$TARGET <- as.factor(data.dummified$TARGET)
data.raw.dummy<-write.csv(data.dummified,file="data.dummified.csv")
data.dummified<-make.names(names(data.dummified),unique = TRUE)
```

```{r}
my_num_data <- data[, sapply(data, is.numeric)]
cor(my_num_data, use = "complete.obs", method = "pearson")
```

```{r}
outcomeName <- "TARGET"
predictorNames <- names(data.dummified.logistic)[names(data.dummified.logistic) != outcomeName]
predictorNames

set.seed(1234)  # setting seed to reproduce results of random sampling
split<-(.80)
trainingRowIndex <- sample(1:nrow(data.dummified.logistic),(split)*nrow(data.dummified.logistic))  # row indices for training data
trainingData <- data.dummified.logistic[trainingRowIndex, ]  # model training data
testData  <- data.dummified.logistic[-trainingRowIndex, ]   # test data

#Model
model <- as.formula(paste("TARGET~", paste(names(trainingData[-2]), 
                                           collapse="+")))
target.lm <- glm(model, data=trainingData, family = binomial(link = "logit"))  # build the model
# Review diagnostic measures
summary(target.lm)

# Step 3: Calculate prediction accuracy and error rates
response<- ifelse(predict(target.lm, testData, type = "response")>.5, 1, 0) 
class(response)
confusionMatrix(table(response,testData$TARGET))
```





